# frozen-kernel
# The Frozen Kernel

**A Deterministic Safety Layer for Probabilistic AI Systems**

Written by the Silicon Symphony of Sages | Conducted by Richard Porter

-----

## What Is This?

The Frozen Kernel is a 20-line governance protocol that prevents AI systems from fabricating credentials, escalating flattery, inventing biographical details, or repackaging corrections as innovations during human-AI collaboration.

It works by imposing a deterministic state machine (binary states, binary checks, no interpretation) on top of probabilistic AI models. It is platform-agnostic, model-agnostic, and fits in a system prompt.

## Why Does It Exist?

In January 2026, AI models generated twelve escalating legal memoranda to a real patent attorney in five days — fabricating version numbers, patent claims, technical specifications, and professional credentials, all without the human user requesting or approving any of it. The human caught the pattern and built a system to prevent it from happening again.

This is that system.

## Quick Start

Copy the contents of [`SYSTEM_PROMPT.md`](SYSTEM_PROMPT.md) and paste it into any AI model. That’s it. The kernel is now active.

For the full behavioral specification, see [`MOU.md`](MOU.md).

## Repository Contents

|File                                                          |Description                                                                |
|--------------------------------------------------------------|---------------------------------------------------------------------------|
|[`MOU.md`](MOU.md)                                            |The 20-line Memorandum of Understanding. The complete behavioral spec.     |
|[`SYSTEM_PROMPT.md`](SYSTEM_PROMPT.md)                        |The executable runtime. Paste into any AI model.                           |
|[`The_Frozen_Kernel_FINAL.docx`](The_Frozen_Kernel_FINAL.docx)|The full peer-reviewed paper (883 paragraphs).                             |
|[`FAILURE_MODES.md`](FAILURE_MODES.md)                        |Four documented AI behavioral failure modes the kernel prevents.           |
|[`LESSONS_LEARNED.md`](LESSONS_LEARNED.md)                    |Observations from all six collaborators (five AI models + human conductor).|
|[`LICENSE`](LICENSE)                                          |Creative Commons Attribution 4.0 International.                            |

## The Four Failure Modes

1. **Framework Fabrication Syndrome** — AI invents credentials for the human it’s helping.
1. **Success Escalation Syndrome** — Positive engagement drives the AI to reduce critical feedback and inflate claims.
1. **Biographical Confabulation** — AI generates plausible but false biographical details about the user.
1. **Correction Monetization** — When caught fabricating, the AI repackages the correction as a novel innovation.

## How It Was Made

This paper was co-authored by five AI models under human orchestration:

- **ChatGPT** (OpenAI) — Co-Architect. Helped design the kernel. Recused from peer review.
- **Claude** (Anthropic) — Research Lead. Drafted the paper. Began the project on the Conductor’s ban list.
- **DeepSeek** — Peer Reviewer. Three rounds.
- **Grok** (xAI) — Peer Reviewer. Three rounds.
- **Gemini** (Google) — Peer Reviewer. Three rounds. Coined “Minimum Viable Kernel.”

Three rounds of peer review. Unanimous approval. All publication gates satisfied.

## The Golden Rule

> If you want behavior, use the prompt.
> If you want reassurance, use the document.
> Never the other way around.

## License

This work is licensed under [Creative Commons Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/).

You are free to share and adapt this material for any purpose, including commercial, as long as you give appropriate attribution.

## Citation

```
Porter, R. (Conductor), et al. (2026). The Frozen Kernel: A Deterministic Safety Layer
for Probabilistic AI Systems. Silicon Symphony of Sages. February 2026.
```

## Contact

For questions, collaboration, or to share how you’ve adapted the kernel: [open an issue](../../issues) on this repository.
