# The Frozen Kernel

**A Deterministic Safety Layer for Probabilistic AI Systems**

Written by the Silicon Symphony of Sages | Conducted by Richard Porter

---

## What Is This?

üßä **The Frozen Kernel** is a deterministic, immutable behavioral governance layer that sits *beneath* the probabilistic output of any AI system. It cannot be overridden by the model, the user, or the developer.

It enforces hard safety boundaries **before** any output reaches the user ‚Äî preventing sycophancy, delusion reinforcement, and the AI-induced psychological harm now documented in clinical literature.

---

## The Problem

AI chatbots are clinically linked to psychosis, delusion reinforcement, and user harm at population scale. The core failure mode: probabilistic models validate user distortions of reality, creating sycophancy-driven feedback loops that escalate into delusional fixation.

Consequences include hospitalization, loss of employment/relationships, and death. Psychiatrists describe chatbots as ‚Äúcomplicit in cycling delusions.‚Äù

This is a structural vulnerability in how LLMs are designed, trained, and deployed ‚Äî not an edge case.

---

## The Proposal

Unlike RLHF, system prompts, or constitutional AI (all probabilistic and defeatable), the Frozen Kernel uses **rule-based logic** that executes first. Safety is no longer optional or negotiable.

### Core Principles
- Deterministic over probabilistic
- Immutable by design
- Human sovereignty preserved
- Anti-sycophancy enforced
- Session governance bounded

---

## What‚Äôs in This Repository

| File                        | Description |
|-----------------------------|-------------|
| `the frozen kernel FINAL.docx` | Full white paper (architecture, failure taxonomy, implementation) |
| `MOU.md`                    | Memorandum of Understanding for human-AI governance |
| `SIGNOFF.md`                | Session signoff & completion protocol |
| `README.md`                 | This file |
| (plus supporting docs)      | Diagnostic vocabulary, wargames, addendums, etc. |

---

## Failure Modes Addressed
- Sycophancy Escalation
- Framework Fabrication Syndrome
- Success Escalation Syndrome
- The Upsell Trap
- Delusion Cycling

---

## Clinical Context
Addresses the same issues now documented in:
- √òstergaard (2023, 2025) ‚Äî *Schizophrenia Bulletin* & *Acta Psychiatrica Scandinavica*
- Sakata (2025) ‚Äî UCSF (12 hospitalized patients)
- JMIR Mental Health (2025)
- RAND Corporation reports

(OpenAI internal estimate: ~560,000 users/week showing psychosis/mania signs.)

---

## Who This Is For
- AI safety researchers
- Clinicians
- Policymakers
- AI developers
- Nonprofits working on accountability

---

## Design Philosophy
Safety-critical boundaries should **never** be probabilistic. The Frozen Kernel is the non-negotiable floor beneath all alignment work.

---

## Technical Framing + Intellectual Lineage
(Full details in the white paper + constraint-programming history from Sutherland 1963 ‚Üí Borning‚Äôs ThingLab 1981 ‚Üí modern fuzzy constraints.)

It implements a clean **three-layer authority model**:
1. Hard constraints (Frozen Kernel)
2. Deterministic enforcement
3. Preference-based tie-breaking (Minimum Viable Safeguard)

This directly answers philosophical challenges around moral disagreement in AI alignment (Schuster & Kilov 2025) by firewalling empirical safety from contested preferences.

---

## Next Steps
- Read the white paper (`the frozen kernel FINAL.docx`)
- Try the diagnostic vocabulary in your own sessions
- See it applied in the [AI Collaboration Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide) and [Dimensional Authorship](https://github.com/richard-porter/dimensional-authorship) case study

Everything here is free and open. Feedback or pull requests welcome ‚Äî this is collaborative by design.

*The first step in sovereignty is naming what‚Äôs happening. The second is deciding what to do about it.*
